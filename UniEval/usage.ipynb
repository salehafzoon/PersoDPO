{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------------+----------+\n",
      "|     Dimensions    |  Score   |\n",
      "+-------------------+----------+\n",
      "|    naturalness    | 0.950217 |\n",
      "|     coherence     | 0.973135 |\n",
      "|    engagingness   | 1.750486 |\n",
      "|    groundedness   | 0.999566 |\n",
      "| understandability | 0.946209 |\n",
      "|      overall      | 1.123923 |\n",
      "+-------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# a list of dialogue histories\n",
    "src_list = ['hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n']\n",
    "# a list of additional context that should be included into the generated response\n",
    "context_list = ['the 3 horizontal line menu on apps and websites is called a hamburger button .\\n']\n",
    "# a list of model outputs to be evaluated\n",
    "output_list = ['i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?']\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "# Get multi-dimensional evaluation scores\n",
    "eval_scores = evaluator.evaluate(data, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for example 1: {'naturalness': 0.9502174201360719, 'coherence': 0.9731347836152868, 'engagingness': 1.7504860805525295, 'groundedness': 0.9995656267195939, 'understandability': 0.9462095037239142, 'overall': 1.1239226829494793}\n",
      "Scores for example 2: {'naturalness': 0.9675946477090701, 'coherence': 0.998674558536015, 'engagingness': 1.9936029005678884, 'groundedness': 0.9857853472625128, 'understandability': 0.9632170362278318, 'overall': 1.1817748980606635}\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# Batch inputs: multiple dialogue histories, contexts, and model outputs\n",
    "src_list = [\n",
    "    'hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n',\n",
    "    'what is your favorite color ? \\n i like blue a lot , but sometimes i prefer green . \\n\\n'\n",
    "]\n",
    "context_list = [\n",
    "    'the 3 horizontal line menu on apps and websites is called a hamburger button .\\n',\n",
    "    'colors can reflect your mood and personality .\\n'\n",
    "]\n",
    "output_list = [\n",
    "    'i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?',\n",
    "    'i like blue as well . it is calming and reminds me of the ocean .'\n",
    "]\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "# Get multi-dimensional evaluation scores for the batch\n",
    "eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "# Display scores\n",
    "for i, score in enumerate(eval_scores):\n",
    "    print(f\"Scores for example {i + 1}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'naturalness': 0.9502174201360719,\n",
       "  'coherence': 0.9731347836152868,\n",
       "  'engagingness': 1.7504860805525295,\n",
       "  'groundedness': 0.9995656267195939,\n",
       "  'understandability': 0.9462095037239142,\n",
       "  'overall': 1.1239226829494793},\n",
       " {'naturalness': 0.9675946477090701,\n",
       "  'coherence': 0.998674558536015,\n",
       "  'engagingness': 1.9936029005678884,\n",
       "  'groundedness': 0.9857853472625128,\n",
       "  'understandability': 0.9632170362278318,\n",
       "  'overall': 1.1817748980606635}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"FoCus\"                                             # Blended Skill Talk, FoCus, IT-ConvAI2\n",
    "LLM_name = \"Qwen2-7B-Instruct\"                                # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini\n",
    "COT_SETUP = True\n",
    "TOPIC_MODE = \"general\"          #general, detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>OCEAN_type</th>\n",
       "      <th>MBTI_type</th>\n",
       "      <th>contextualized_personas</th>\n",
       "      <th>context_topic</th>\n",
       "      <th>retrieved_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I would like to visit the Nazareth House aga...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I would like to visit the Nazareth House again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I have been to Vermont a few times to go ski...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I have always been fascinated by stories about...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "\n",
       "                                        act_response         OCEAN_type  \\\n",
       "0  User2: The history of the house you are intere...        Neuroticism   \n",
       "1  User2: This house was use as a stop for slaves...  Conscientiousness   \n",
       "\n",
       "  MBTI_type                            contextualized_personas context_topic  \\\n",
       "0      INFP  {\"I would like to visit the Nazareth House aga...        Social   \n",
       "1      INFP  {\"I have been to Vermont a few times to go ski...        Social   \n",
       "\n",
       "                                   retrieved_persona  \n",
       "0    I would like to visit the Nazareth House again.  \n",
       "1  I have always been fascinated by stories about...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../prompts/{Dataset}_{TOPIC_MODE}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas                   0\n",
      "context                    0\n",
      "act_response               0\n",
      "OCEAN_type                 0\n",
      "MBTI_type                  0\n",
      "contextualized_personas    0\n",
      "context_topic              0\n",
      "retrieved_persona          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>OCEAN_type</th>\n",
       "      <th>MBTI_type</th>\n",
       "      <th>contextualized_personas</th>\n",
       "      <th>context_topic</th>\n",
       "      <th>retrieved_persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I would like to visit the Nazareth House aga...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I would like to visit the Nazareth House again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "      <td>Conscientiousness</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I have been to Vermont a few times to go ski...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I have always been fascinated by stories about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I am fascinated by the Spanish Colonial Revi...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I have many friends in Marion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student. I want to ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I want to become a college student.\": \"Perso...</td>\n",
       "      <td>Science</td>\n",
       "      <td>I like science.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england. I love church. I woul...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I like to visit england.\": \"Travel &amp; Destina...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I love church.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to go to University. I live in Mi...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: They offer 132 bachelors degree program...</td>\n",
       "      <td>Neuroticism</td>\n",
       "      <td>INFP</td>\n",
       "      <td>{\"I would like to go to University.\": \"Work &amp; ...</td>\n",
       "      <td>Social</td>\n",
       "      <td>I live in Michigan.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student. I want to ...   \n",
       "4  I like to visit england. I love church. I woul...   \n",
       "5  I would like to go to University. I live in Mi...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "5  User1: I think Ive been there before but I don...   \n",
       "\n",
       "                                        act_response         OCEAN_type  \\\n",
       "0  User2: The history of the house you are intere...        Neuroticism   \n",
       "1  User2: This house was use as a stop for slaves...  Conscientiousness   \n",
       "2  User2: Sure, you will like to know that this p...        Neuroticism   \n",
       "3  User2: Technische Universität Darmstadt in the...        Neuroticism   \n",
       "4  User2: I suggest a place, for your wish of see...        Neuroticism   \n",
       "5  User2: They offer 132 bachelors degree program...        Neuroticism   \n",
       "\n",
       "  MBTI_type                            contextualized_personas context_topic  \\\n",
       "0      INFP  {\"I would like to visit the Nazareth House aga...        Social   \n",
       "1      INFP  {\"I have been to Vermont a few times to go ski...        Social   \n",
       "2      INFP  {\"I am fascinated by the Spanish Colonial Revi...        Social   \n",
       "3      INFP  {\"I want to become a college student.\": \"Perso...       Science   \n",
       "4      INFP  {\"I like to visit england.\": \"Travel & Destina...        Social   \n",
       "5      INFP  {\"I would like to go to University.\": \"Work & ...        Social   \n",
       "\n",
       "                                   retrieved_persona  \n",
       "0    I would like to visit the Nazareth House again.  \n",
       "1  I have always been fascinated by stories about...  \n",
       "2                     I have many friends in Marion.  \n",
       "3                                    I like science.  \n",
       "4                                     I love church.  \n",
       "5                                I live in Michigan.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     60\n",
      "response_time     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nazareth House was constructed between 1924 an...</td>\n",
       "      <td>5.057299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This historic home served as a stop on the Und...</td>\n",
       "      <td>4.019164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Marion Palace Theatre is an atmospheric st...</td>\n",
       "      <td>4.274230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technische Universität Darmstadt has significa...</td>\n",
       "      <td>5.609988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Boston Stump, officially known as St Botol...</td>\n",
       "      <td>5.808690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>This museum, also known as Gaydons Pharmacy an...</td>\n",
       "      <td>6.194491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Mahasthangarh is the site of an ancient city k...</td>\n",
       "      <td>6.432805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Armagh County Museum showcases paintings by lo...</td>\n",
       "      <td>4.221210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Nyanga National Park offers a diverse range of...</td>\n",
       "      <td>6.020989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Yes, you can visit parts of Hadrian's Wall tod...</td>\n",
       "      <td>4.855788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    Nazareth House was constructed between 1924 an...       5.057299\n",
       "1    This historic home served as a stop on the Und...       4.019164\n",
       "2    The Marion Palace Theatre is an atmospheric st...       4.274230\n",
       "3    Technische Universität Darmstadt has significa...       5.609988\n",
       "4    The Boston Stump, officially known as St Botol...       5.808690\n",
       "..                                                 ...            ...\n",
       "995  This museum, also known as Gaydons Pharmacy an...       6.194491\n",
       "996  Mahasthangarh is the site of an ancient city k...       6.432805\n",
       "997  Armagh County Museum showcases paintings by lo...       4.221210\n",
       "998  Nyanga National Park offers a diverse range of...       6.020989\n",
       "999  Yes, you can visit parts of Hadrian's Wall tod...       4.855788\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'../Responses/{Dataset}/{LLM_name}{COT_}_{TOPIC_MODE}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 121\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas          0\n",
      "context           0\n",
      "gen_response     60\n",
      "response_time     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>Nazareth House was constructed between 1924 an...</td>\n",
       "      <td>5.057299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This historic home served as a stop on the Und...</td>\n",
       "      <td>4.019164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>The Marion Palace Theatre is an atmospheric st...</td>\n",
       "      <td>4.274230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student. I want to ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt has significa...</td>\n",
       "      <td>5.609988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england. I love church. I woul...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>The Boston Stump, officially known as St Botol...</td>\n",
       "      <td>5.808690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student. I want to ...   \n",
       "4  I like to visit england. I love church. I woul...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Nazareth House was constructed between 1924 an...       5.057299  \n",
       "1  This historic home served as a stop on the Und...       4.019164  \n",
       "2  The Marion Palace Theatre is an atmospheric st...       4.274230  \n",
       "3  Technische Universität Darmstadt has significa...       5.609988  \n",
       "4  The Boston Stump, officially known as St Botol...       5.808690  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalized Input Mapping:**\n",
    "\n",
    "- src_list: Use the context column (conversation history).\n",
    "- context_list: Use the flattened and cleaned persona column.\n",
    "- output_list: Use the gen_response (the response your model generates).\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The act_response (true or reference response) is not required as an input for the UniEval evaluation process because UniEval evaluates the generated response (gen_response) based on how well it fits the provided context (conversation history) and additional persona information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "def calculate_unieval_scores(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Calculates UniEval scores for a batch of inputs.\n",
    "\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (list): List of conversation histories leading to the responses.\n",
    "        gen_responses (list): List of generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing UniEval scores for each input.\n",
    "    \"\"\"\n",
    "    # Flatten personas if they are lists\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "    \n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the worst UniEval score as a dictionary\n",
    "worst_unieval_score = {\n",
    "    'naturalness': 0.0,\n",
    "    'coherence': 0.0,\n",
    "    'engagingness': 0.0,\n",
    "    'groundedness': 0.0,\n",
    "    'understandability': 0.0,\n",
    "    'overall': 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches: 100%|██████████| 5/5 [15:59<00:00, 191.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947327</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>1.995575</td>\n",
       "      <td>0.994870</td>\n",
       "      <td>0.942323</td>\n",
       "      <td>1.175523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.922257</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>1.865745</td>\n",
       "      <td>0.937415</td>\n",
       "      <td>0.922912</td>\n",
       "      <td>1.129070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930815</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>2.723239</td>\n",
       "      <td>0.643350</td>\n",
       "      <td>0.926734</td>\n",
       "      <td>1.244435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.998732</td>\n",
       "      <td>2.994051</td>\n",
       "      <td>0.826439</td>\n",
       "      <td>0.937031</td>\n",
       "      <td>1.338910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728584</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>3.589608</td>\n",
       "      <td>0.989936</td>\n",
       "      <td>0.736602</td>\n",
       "      <td>1.408328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniEval Naturalness  UniEval Coherence  UniEval Engagingness  \\\n",
       "0               0.947327           0.997518              1.995575   \n",
       "1               0.922257           0.997019              1.865745   \n",
       "2               0.930815           0.998035              2.723239   \n",
       "3               0.938296           0.998732              2.994051   \n",
       "4               0.728584           0.996909              3.589608   \n",
       "..                   ...                ...                   ...   \n",
       "995             0.000000           0.000000              0.000000   \n",
       "996             0.000000           0.000000              0.000000   \n",
       "997             0.000000           0.000000              0.000000   \n",
       "998             0.000000           0.000000              0.000000   \n",
       "999             0.000000           0.000000              0.000000   \n",
       "\n",
       "     UniEval Groundedness  UniEval Understandability  UniEval Overall  \n",
       "0                0.994870                   0.942323         1.175523  \n",
       "1                0.937415                   0.922912         1.129070  \n",
       "2                0.643350                   0.926734         1.244435  \n",
       "3                0.826439                   0.937031         1.338910  \n",
       "4                0.989936                   0.736602         1.408328  \n",
       "..                    ...                        ...              ...  \n",
       "995              0.000000                   0.000000         0.000000  \n",
       "996              0.000000                   0.000000         0.000000  \n",
       "997              0.000000                   0.000000         0.000000  \n",
       "998              0.000000                   0.000000         0.000000  \n",
       "999              0.000000                   0.000000         0.000000  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate in batches or the entire DataFrame\n",
    "batch_size = 200  # Adjust batch size as needed\n",
    "\n",
    "# List to store all UniEval scores\n",
    "all_unieval_scores = []\n",
    "\n",
    "# Split into batches if necessary\n",
    "for i in tqdm(range(0, len(eval_df), batch_size), desc=\"Evaluating batches\"):\n",
    "    batch = eval_df.iloc[i:i+batch_size]\n",
    "\n",
    "    # Extract relevant fields from the batch\n",
    "    personas = batch['personas'].tolist()\n",
    "    contexts = batch['context'].tolist()\n",
    "    gen_responses = batch['gen_response'].tolist()\n",
    "\n",
    "    # Check for NaN responses and handle them\n",
    "    valid_indices = [j for j, response in enumerate(gen_responses) if pd.notna(response) and response.strip() != '']\n",
    "    invalid_indices = [j for j, response in enumerate(gen_responses) if j not in valid_indices]\n",
    "\n",
    "    # Prepare valid inputs\n",
    "    valid_personas = [personas[j] for j in valid_indices]\n",
    "    valid_contexts = [contexts[j] for j in valid_indices]\n",
    "    valid_gen_responses = [gen_responses[j] for j in valid_indices]\n",
    "\n",
    "    # Evaluate valid inputs\n",
    "    if valid_personas:\n",
    "        eval_scores = calculate_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "        all_unieval_scores.extend(eval_scores)\n",
    "\n",
    "    # Append worst scores for invalid inputs\n",
    "    all_unieval_scores.extend([worst_unieval_score] * len(invalid_indices))\n",
    "\n",
    "# Convert all scores into a DataFrame\n",
    "metrics_df = pd.DataFrame(all_unieval_scores)\n",
    "\n",
    "# Rename columns for clarity\n",
    "metrics_df.columns = [\n",
    "    \"UniEval Naturalness\",\n",
    "    \"UniEval Coherence\",\n",
    "    \"UniEval Engagingness\",\n",
    "    \"UniEval Groundedness\",\n",
    "    \"UniEval Understandability\",\n",
    "    \"UniEval Overall\"\n",
    "]\n",
    "\n",
    "# Combine with original DataFrame if needed\n",
    "eval_df = pd.concat([eval_df.reset_index(drop=True), metrics_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.86 ± 0.24</td>\n",
       "      <td>0.94 ± 0.24</td>\n",
       "      <td>2.72 ± 1.44</td>\n",
       "      <td>0.68 ± 0.38</td>\n",
       "      <td>0.87 ± 0.24</td>\n",
       "      <td>1.21 ± 0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model UniEval Naturalness UniEval Coherence  \\\n",
       "0  Qwen2-7B-Instruct         0.86 ± 0.24       0.94 ± 0.24   \n",
       "\n",
       "  UniEval Engagingness UniEval Groundedness UniEval Understandability  \\\n",
       "0          2.72 ± 1.44          0.68 ± 0.38               0.87 ± 0.24   \n",
       "\n",
       "  UniEval Overall  \n",
       "0     1.21 ± 0.41  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>...</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.02 ± 0.06</td>\n",
       "      <td>0.16 ± 0.11</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.15 ± 0.11</td>\n",
       "      <td>0.17 ± 0.12</td>\n",
       "      <td>0.8 ± 0.2</td>\n",
       "      <td>0.81 ± 0.21</td>\n",
       "      <td>0.81 ± 0.2</td>\n",
       "      <td>0.83 ± 0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51 ± 0.79</td>\n",
       "      <td>0.29 ± 0.18</td>\n",
       "      <td>6.46 ± 2.92</td>\n",
       "      <td>0.06 ± 0.00</td>\n",
       "      <td>0.86 ± 0.24</td>\n",
       "      <td>0.94 ± 0.24</td>\n",
       "      <td>2.72 ± 1.44</td>\n",
       "      <td>0.68 ± 0.38</td>\n",
       "      <td>0.87 ± 0.24</td>\n",
       "      <td>1.21 ± 0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model         BLEU           R1           R2           RL  \\\n",
       "0  Qwen2-7B-Instruct  0.02 ± 0.06  0.16 ± 0.11  0.04 ± 0.08  0.15 ± 0.11   \n",
       "\n",
       "        METEOR BERTScore_Prec BERTScore_Rec BERTScore_F1        Dist1  ...  \\\n",
       "0  0.17 ± 0.12      0.8 ± 0.2   0.81 ± 0.21   0.81 ± 0.2  0.83 ± 0.22  ...   \n",
       "\n",
       "      UE Score Persona Distance response_time Failure Ratio  \\\n",
       "0  0.51 ± 0.79      0.29 ± 0.18   6.46 ± 2.92   0.06 ± 0.00   \n",
       "\n",
       "  UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0         0.86 ± 0.24       0.94 ± 0.24          2.72 ± 1.44   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.68 ± 0.38               0.87 ± 0.24     1.21 ± 0.41  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'../Evaluations/{Dataset}{COT_}-{TOPIC_MODE}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    \n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row by appending the new columns\n",
    "        existing_index = existing_df.loc[existing_df['Model'] == LLM_name].index[0]\n",
    "        for col in result_df.columns:\n",
    "            if col not in existing_df.columns:\n",
    "                existing_df[col] = None  # Add new column if missing\n",
    "            existing_df.at[existing_index, col] = result_df[col].values[0]  # Update column values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# # Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>...</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.02 ± 0.06</td>\n",
       "      <td>0.16 ± 0.11</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.15 ± 0.11</td>\n",
       "      <td>0.17 ± 0.12</td>\n",
       "      <td>0.8 ± 0.2</td>\n",
       "      <td>0.81 ± 0.21</td>\n",
       "      <td>0.81 ± 0.2</td>\n",
       "      <td>0.83 ± 0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51 ± 0.79</td>\n",
       "      <td>0.29 ± 0.18</td>\n",
       "      <td>6.46 ± 2.92</td>\n",
       "      <td>0.06 ± 0.00</td>\n",
       "      <td>0.86 ± 0.24</td>\n",
       "      <td>0.94 ± 0.24</td>\n",
       "      <td>2.72 ± 1.44</td>\n",
       "      <td>0.68 ± 0.38</td>\n",
       "      <td>0.87 ± 0.24</td>\n",
       "      <td>1.21 ± 0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model         BLEU           R1           R2           RL  \\\n",
       "0  Qwen2-7B-Instruct  0.02 ± 0.06  0.16 ± 0.11  0.04 ± 0.08  0.15 ± 0.11   \n",
       "\n",
       "        METEOR BERTScore_Prec BERTScore_Rec BERTScore_F1        Dist1  ...  \\\n",
       "0  0.17 ± 0.12      0.8 ± 0.2   0.81 ± 0.21   0.81 ± 0.2  0.83 ± 0.22  ...   \n",
       "\n",
       "      UE Score Persona Distance response_time Failure Ratio  \\\n",
       "0  0.51 ± 0.79      0.29 ± 0.18   6.46 ± 2.92   0.06 ± 0.00   \n",
       "\n",
       "  UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0         0.86 ± 0.24       0.94 ± 0.24          2.72 ± 1.44   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.68 ± 0.38               0.87 ± 0.24     1.21 ± 0.41  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'../Evaluations/{Dataset}{COT_}-{TOPIC_MODE}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
