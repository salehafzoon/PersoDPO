{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim requests rouge bert_score openpyxl prettytable nltk gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# import gzip\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# compressed_path = \"./GoogleNews-vectors-negative300.bin.gz\"\n",
    "# decompressed_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "\n",
    "# # Google Drive file ID extracted from the link\n",
    "# file_id = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
    "\n",
    "# # Download the file\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}&export=download\", compressed_path, quiet=False)\n",
    "\n",
    "# print(\"Download completed.\")\n",
    "\n",
    "\n",
    "# # Extract the .bin file from .gz\n",
    "# with gzip.open(compressed_path, \"rb\") as f_in:\n",
    "#     with open(decompressed_path, \"wb\") as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# print(\"Extraction completed.\")\n",
    "\n",
    "# # (Optional) Delete the .gz file after extraction\n",
    "# os.remove(compressed_path)\n",
    "# print(\"Deleted the compressed file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"FoCus\"                      \n",
    "\n",
    "COT_ = \"\"                                   #  \"\",    \"-COT\"\n",
    "\n",
    "\n",
    "SET = \"train\"\n",
    "LLM = f\"Qwen2-7B-Instruct-{SET}\"\n",
    "\n",
    "\n",
    "# SCORING_METHOD = \"avg\"                      # \"avg\",  \"length_prior\"\n",
    "# LLM = f\"Qwen2-5B-{DATASET}-{SCORING_METHOD}\"\n",
    "\n",
    "\n",
    "COT_SETUP = True if COT_ == \"-COT\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: You can access Descent of the Ganges vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>User2: It was Sherman School.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: You can access Descent of the Ganges vi...  \n",
       "1                      User2: It was Sherman School.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{DATASET}-{SET}.csv')\n",
    "\n",
    "\n",
    "# df = pd.read_csv(f'./Prompts/{DATASET}.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>You can access Descent of the Ganges via Chenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It was Sherman School.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "\n",
       "                                        act_response  \n",
       "0  You can access Descent of the Ganges via Chenn...  \n",
       "1                             It was Sherman School.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "\n",
    "df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     1254\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.212004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.141517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.168975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.286672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.294671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The Pelican Island National Wildlife Refuge is...</td>\n",
       "      <td>3.926378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>The neighborhood today is quite different from...</td>\n",
       "      <td>4.008988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Yes, it's quite accessible! The National Archi...</td>\n",
       "      <td>3.260124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>The Alhambra Creek is a beautiful stream locat...</td>\n",
       "      <td>4.147906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>I've heard about the Brickyard 400, but I'm no...</td>\n",
       "      <td>3.289213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_response  response_time\n",
       "0                                                   NaN       4.212004\n",
       "1                                                   NaN       4.141517\n",
       "2                                                   NaN       4.168975\n",
       "3                                                   NaN       4.286672\n",
       "4                                                   NaN       4.294671\n",
       "...                                                 ...            ...\n",
       "1995  The Pelican Island National Wildlife Refuge is...       3.926378\n",
       "1996  The neighborhood today is quite different from...       4.008988\n",
       "1997  Yes, it's quite accessible! The National Archi...       3.260124\n",
       "1998  The Alhambra Creek is a beautiful stream locat...       4.147906\n",
       "1999  I've heard about the Brickyard 400, but I'm no...       3.289213\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_csv(f'Responses/{DATASET}/{LLM}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 92\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas            0\n",
      "context             0\n",
      "act_response        0\n",
      "gen_response     1254\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>You can access Descent of the Ganges via Chenn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.212004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It was Sherman School.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.141517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love cool lakes.I would like to visit the Hi...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It formed from being a tributary of the Ravi R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.168975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I prefer outdoor stadium over indoor stadium.I...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I just remembered that you are interested in N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.286672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would like to visit Spain.I am interested in...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This is Ur...</td>\n",
       "      <td>Urdaibai Bird Center deals with two main tasks...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.294671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "2  I love cool lakes.I would like to visit the Hi...   \n",
       "3  I prefer outdoor stadium over indoor stadium.I...   \n",
       "4  I would like to visit Spain.I am interested in...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "2  User1: I know this place, but I dont remember ...   \n",
       "3  User1: Where is this place?\\nUser2: This place...   \n",
       "4  User1: Where is this place?\\nUser2: This is Ur...   \n",
       "\n",
       "                                        act_response gen_response  \\\n",
       "0  You can access Descent of the Ganges via Chenn...          NaN   \n",
       "1                             It was Sherman School.          NaN   \n",
       "2  It formed from being a tributary of the Ravi R...          NaN   \n",
       "3  I just remembered that you are interested in N...          NaN   \n",
       "4  Urdaibai Bird Center deals with two main tasks...          NaN   \n",
       "\n",
       "   response_time  \n",
       "0       4.212004  \n",
       "1       4.141517  \n",
       "2       4.168975  \n",
       "3       4.286672  \n",
       "4       4.294671  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas            0\n",
      "context             0\n",
      "act_response        0\n",
      "gen_response     1254\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Add UniEval to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"UniEval\"))  # Update with your actual path\n",
    "\n",
    "from UniEval.utils import convert_to_json\n",
    "from UniEval.metric.evaluator import get_evaluator\n",
    "\n",
    "\n",
    "# Lists to store the metrics\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "persona_distance_scores = []\n",
    "coh_unieval_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_c_scores(gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_c_score using DNLI model.\n",
    "    \"\"\"\n",
    "    assert len(gen_responses) == len(personas), \"Mismatched input lengths\"\n",
    "\n",
    "    inputs = [f\"{p} {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    results = bert_on_dnli(inputs)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        label = label_mapping.get(result['label'], 'unknown')\n",
    "        if label == 'positive':\n",
    "            scores.append(1)\n",
    "        elif label == 'neutral':\n",
    "            scores.append(0)\n",
    "        elif label == 'negative':\n",
    "            scores.append(-1)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def batch_calculate_ue_scores(act_responses, gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_ue_score using SNLI model.\n",
    "    Returns a list of UE scores (0, 1, or 2).\n",
    "    \"\"\"\n",
    "    assert len(act_responses) == len(gen_responses) == len(personas), \"Mismatched lengths.\"\n",
    "\n",
    "    # Prepare NLI inputs\n",
    "    inputs_pr = [f\"{p} [SEP] {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    inputs_qr = [f\"{q} [SEP] {r}\" for q, r in zip(act_responses, gen_responses)]\n",
    "\n",
    "    # Run both batches\n",
    "    results_pr = bert_on_snli(inputs_pr)\n",
    "    results_qr = bert_on_snli(inputs_qr)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for res_pr, res_qr in zip(results_pr, results_qr):\n",
    "        label_pr = label_mapping.get(res_pr['label'], 'unknown')\n",
    "        label_qr = label_mapping.get(res_qr['label'], 'unknown')\n",
    "\n",
    "        if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "            scores.append(2)\n",
    "        elif label_pr == 'entailment':\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_coh_unieval_scores(personas_list, contexts_list, gen_responses_list):\n",
    "    \"\"\"\n",
    "    Batched coherence scoring using UniEval evaluator.\n",
    "    \"\"\"\n",
    "    # Ensure personas are joined as single strings\n",
    "    personas_list = [' '.join(p) if isinstance(p, list) else p for p in personas_list]\n",
    "    \n",
    "    # Convert to UniEval input format\n",
    "    data = convert_to_json(\n",
    "        output_list=gen_responses_list,\n",
    "        src_list=contexts_list,\n",
    "        context_list=personas_list\n",
    "    )\n",
    "    \n",
    "    # Load UniEval dialogue evaluator only once\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    # Extract coherence scores\n",
    "    return [s.get(\"coherence\", None) for s in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_c_score = -1.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0\n",
    "worst_coh_unieval_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating C Scores...\n",
      "Calculating UE Scores...\n",
      "Calculating UniEval Coherence Scores...\n",
      "Filling final metric arrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating Scores: 100%|██████████| 746/746 [00:00<00:00, 646611.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Identify valid rows (non-null gen_response)\n",
    "valid_mask = eval_df['gen_response'].notna()\n",
    "valid_indices = eval_df[valid_mask].index.tolist()\n",
    "\n",
    "# Extract valid inputs\n",
    "valid_personas = eval_df.loc[valid_indices, 'personas'].tolist()\n",
    "valid_act_responses = eval_df.loc[valid_indices, 'act_response'].tolist()\n",
    "valid_contexts = eval_df.loc[valid_indices, 'context'].tolist()\n",
    "valid_gen_responses = eval_df.loc[valid_indices, 'gen_response'].tolist()\n",
    "\n",
    "# === Compute batch metrics with tqdm logging ===\n",
    "print(\"Calculating C Scores...\")\n",
    "c_scores_batch = batch_calculate_c_scores(valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UE Scores...\")\n",
    "ue_scores_batch = batch_calculate_ue_scores(valid_act_responses, valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UniEval Coherence Scores...\")\n",
    "coh_unieval_batch_scores = batch_calculate_coh_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "\n",
    "# Initialize all score lists with worst-case values\n",
    "c_scores = [worst_c_score] * len(eval_df)\n",
    "ue_scores = [worst_ue_score] * len(eval_df)\n",
    "coh_unieval_scores = [worst_coh_unieval_score] * len(eval_df)\n",
    "\n",
    "# Fill valid indices with batch results using progress bar\n",
    "print(\"Filling final metric arrays...\")\n",
    "for i, c, ue, coh in tqdm(zip(valid_indices, c_scores_batch, ue_scores_batch, coh_unieval_batch_scores),\n",
    "                          total=len(valid_indices), desc=\"Populating Scores\"):\n",
    "    c_scores[i] = c\n",
    "    ue_scores[i] = ue\n",
    "    coh_unieval_scores[i] = coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 7171.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.998527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.999321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.999496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0        0.000000     -1.0       0.0          0.000000\n",
       "1        0.000000     -1.0       0.0          0.000000\n",
       "2        0.000000     -1.0       0.0          0.000000\n",
       "3        0.000000     -1.0       0.0          0.000000\n",
       "4        0.000000     -1.0       0.0          0.000000\n",
       "...           ...      ...       ...               ...\n",
       "1995     0.998527      1.0       0.0          0.454356\n",
       "1996     0.999321      1.0       0.0          0.650509\n",
       "1997     0.998446      0.0       0.0          0.517190\n",
       "1998     0.999496      1.0       0.0          0.606287\n",
       "1999     0.999350      0.0       0.0          0.667512\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    contexts = row['context']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "    \n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "    \n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    persona_distance_scores.append(compute_persona_distance(personas, gen_response, word2vec_model,stop_words))\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Coh-UniEval': coh_unieval_scores,\n",
    "    'C Score': c_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the full results\n",
    "output_path = f'./Metrics Results/{DATASET}/{LLM}{COT_}-results.xlsx'\n",
    "\n",
    "df_concat = pd.concat([eval_df, metrics_df], axis=1)\n",
    "\n",
    "df_concat.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.212004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.141517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.168975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.286672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.294671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3.926378</td>\n",
       "      <td>0.998527</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4.008988</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3.260124</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4.147906</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.606287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3.289213</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      response_time  Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0          4.212004     0.000000       -1         0          0.000000\n",
       "1          4.141517     0.000000       -1         0          0.000000\n",
       "2          4.168975     0.000000       -1         0          0.000000\n",
       "3          4.286672     0.000000       -1         0          0.000000\n",
       "4          4.294671     0.000000       -1         0          0.000000\n",
       "...             ...          ...      ...       ...               ...\n",
       "1995       3.926378     0.998527        1         0          0.454356\n",
       "1996       4.008988     0.999321        1         0          0.650509\n",
       "1997       3.260124     0.998446        0         0          0.517190\n",
       "1998       4.147906     0.999496        1         0          0.606287\n",
       "1999       3.289213     0.999350        0         0          0.667512\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(f\"Metrics Results/{DATASET}/{LLM}-results.xlsx\")\n",
    "metrics_df = df.drop(columns=[\"personas\", \"context\", \"act_response\",\"gen_response\"])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-Instruct-train</td>\n",
       "      <td>3.99 ± 0.54</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.15 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model response_time  Coh-UniEval       C Score  \\\n",
       "0  Qwen2-7B-Instruct-train   3.99 ± 0.54  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.15 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = df['gen_response'].isna().sum() /len(df) \n",
    "\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-Benchmark</td>\n",
       "      <td>0.77 ± 0.16</td>\n",
       "      <td>0.6 ± 0.49</td>\n",
       "      <td>-0.24 ± 0.76</td>\n",
       "      <td>0.14 ± 0.45</td>\n",
       "      <td>0.3 ± 0.26</td>\n",
       "      <td>0.39 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-DPO-AVG</td>\n",
       "      <td>0.85 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-DPO-LENGTH-PRIOR</td>\n",
       "      <td>0.6 ± 0.17</td>\n",
       "      <td>0.8 ± 0.39</td>\n",
       "      <td>0.03 ± 0.69</td>\n",
       "      <td>0.34 ± 0.67</td>\n",
       "      <td>0.4 ± 0.22</td>\n",
       "      <td>0.149 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen2-5B-DPO</td>\n",
       "      <td>0.86 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-5B-FoCus-length_prior</td>\n",
       "      <td>0.83 ± 0.12</td>\n",
       "      <td>0.48 ± 0.47</td>\n",
       "      <td>-0.18 ± 0.62</td>\n",
       "      <td>0.32 ± 0.68</td>\n",
       "      <td>0.27 ± 0.19</td>\n",
       "      <td>0.241 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qwen2-7B-Instruct-train</td>\n",
       "      <td>3.99 ± 0.54</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.15 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model response_time  Coh-UniEval       C Score  \\\n",
       "0           Qwen2-5B-Benchmark   0.77 ± 0.16   0.6 ± 0.49  -0.24 ± 0.76   \n",
       "1             Qwen2-5B-DPO-AVG   0.85 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "2    Qwen2-5B-DPO-LENGTH-PRIOR    0.6 ± 0.17   0.8 ± 0.39   0.03 ± 0.69   \n",
       "3                 Qwen2-5B-DPO   0.86 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "4  Qwen2-5B-FoCus-length_prior   0.83 ± 0.12  0.48 ± 0.47  -0.18 ± 0.62   \n",
       "5      Qwen2-7B-Instruct-train   3.99 ± 0.54  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.14 ± 0.45       0.3 ± 0.26   0.39 ± 0.00  \n",
       "1  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "2  0.34 ± 0.67       0.4 ± 0.22  0.149 ± 0.00  \n",
       "3  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "4  0.32 ± 0.68      0.27 ± 0.19  0.241 ± 0.00  \n",
       "5  0.15 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{DATASET}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviwing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-Benchmark</td>\n",
       "      <td>0.77 ± 0.16</td>\n",
       "      <td>0.6 ± 0.49</td>\n",
       "      <td>-0.24 ± 0.76</td>\n",
       "      <td>0.14 ± 0.45</td>\n",
       "      <td>0.3 ± 0.26</td>\n",
       "      <td>0.39 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-DPO-AVG</td>\n",
       "      <td>0.85 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-DPO-LENGTH-PRIOR</td>\n",
       "      <td>0.6 ± 0.17</td>\n",
       "      <td>0.8 ± 0.39</td>\n",
       "      <td>0.03 ± 0.69</td>\n",
       "      <td>0.34 ± 0.67</td>\n",
       "      <td>0.4 ± 0.22</td>\n",
       "      <td>0.149 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen2-5B-DPO</td>\n",
       "      <td>0.86 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-5B-FoCus-length_prior</td>\n",
       "      <td>0.83 ± 0.12</td>\n",
       "      <td>0.48 ± 0.47</td>\n",
       "      <td>-0.18 ± 0.62</td>\n",
       "      <td>0.32 ± 0.68</td>\n",
       "      <td>0.27 ± 0.19</td>\n",
       "      <td>0.241 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model response_time  Coh-UniEval       C Score  \\\n",
       "0           Qwen2-5B-Benchmark   0.77 ± 0.16   0.6 ± 0.49  -0.24 ± 0.76   \n",
       "1             Qwen2-5B-DPO-AVG   0.85 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "2    Qwen2-5B-DPO-LENGTH-PRIOR    0.6 ± 0.17   0.8 ± 0.39   0.03 ± 0.69   \n",
       "3                 Qwen2-5B-DPO   0.86 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "4  Qwen2-5B-FoCus-length_prior   0.83 ± 0.12  0.48 ± 0.47  -0.18 ± 0.62   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.14 ± 0.45       0.3 ± 0.26   0.39 ± 0.00  \n",
       "1  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "2  0.34 ± 0.67       0.4 ± 0.22  0.149 ± 0.00  \n",
       "3  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "4  0.32 ± 0.68      0.27 ± 0.19  0.241 ± 0.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET = \"FoCus\"  \n",
    "# # COT_ = \"-COT\"\n",
    "# COT_ =  \"\"\n",
    "\n",
    "response = pd.read_excel(f'./Evaluations/{DATASET}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
