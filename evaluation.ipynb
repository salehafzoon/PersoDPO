{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim requests rouge bert_score openpyxl prettytable nltk gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# import gzip\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# compressed_path = \"./GoogleNews-vectors-negative300.bin.gz\"\n",
    "# decompressed_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "\n",
    "# # Google Drive file ID extracted from the link\n",
    "# file_id = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
    "\n",
    "# # Download the file\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}&export=download\", compressed_path, quiet=False)\n",
    "\n",
    "# print(\"Download completed.\")\n",
    "\n",
    "\n",
    "# # Extract the .bin file from .gz\n",
    "# with gzip.open(compressed_path, \"rb\") as f_in:\n",
    "#     with open(decompressed_path, \"wb\") as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# print(\"Extraction completed.\")\n",
    "\n",
    "# # (Optional) Delete the .gz file after extraction\n",
    "# os.remove(compressed_path)\n",
    "# print(\"Deleted the compressed file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"FoCus\"                                             \n",
    "\n",
    "# LLM = \"Qwen2-5B-Benchmark\"     \n",
    "# LLM = \"Qwen2-5B-DPO-AVG\"     \n",
    "LLM = \"Qwen2-5B-DPO-LENGTH-PRIOR\"   \n",
    "                              \n",
    "COT_SETUP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{DATASET}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "\n",
       "                                        act_response  \n",
       "0  The history of the house you are interested in...  \n",
       "1  This house was use as a stop for slaves trying...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "\n",
    "df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     203\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Nazareth House is a historic institution l...</td>\n",
       "      <td>0.514938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Truman Galusha House is a historic house l...</td>\n",
       "      <td>0.462074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Marion Palace Theatre is a movie palace lo...</td>\n",
       "      <td>0.422826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technische Universität Darmstadt is a renowned...</td>\n",
       "      <td>0.634715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's a suggestion for visiting England: Bost...</td>\n",
       "      <td>0.444070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Sure, let me provide you with a personalized r...</td>\n",
       "      <td>0.409802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Nyanga National Park is located in Botswana, a...</td>\n",
       "      <td>0.517449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Hadrian Wall is an ancient fortification built...</td>\n",
       "      <td>0.745065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    The Nazareth House is a historic institution l...       0.514938\n",
       "1    The Truman Galusha House is a historic house l...       0.462074\n",
       "2    The Marion Palace Theatre is a movie palace lo...       0.422826\n",
       "3    Technische Universität Darmstadt is a renowned...       0.634715\n",
       "4    Here's a suggestion for visiting England: Bost...       0.444070\n",
       "..                                                 ...            ...\n",
       "995                                                NaN       0.884238\n",
       "996  Sure, let me provide you with a personalized r...       0.409802\n",
       "997                                                NaN       0.899150\n",
       "998  Nyanga National Park is located in Botswana, a...       0.517449\n",
       "999  Hadrian Wall is an ancient fortification built...       0.745065\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    "\n",
    "response = pd.read_csv(f'Responses/{DATASET}/{LLM}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 71\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas           0\n",
      "context            0\n",
      "act_response       0\n",
      "gen_response     203\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "      <td>The Nazareth House is a historic institution l...</td>\n",
       "      <td>0.514938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "      <td>The Truman Galusha House is a historic house l...</td>\n",
       "      <td>0.462074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "      <td>The Marion Palace Theatre is a movie palace lo...</td>\n",
       "      <td>0.422826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "      <td>Technische Universität Darmstadt is a renowned...</td>\n",
       "      <td>0.634715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "      <td>Here's a suggestion for visiting England: Bost...</td>\n",
       "      <td>0.444070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  The history of the house you are interested in...   \n",
       "1  This house was use as a stop for slaves trying...   \n",
       "2  Sure, you will like to know that this place wa...   \n",
       "3  Technische Universität Darmstadt in the top 25...   \n",
       "4  I suggest a place, for your wish of see librar...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  The Nazareth House is a historic institution l...       0.514938  \n",
       "1  The Truman Galusha House is a historic house l...       0.462074  \n",
       "2  The Marion Palace Theatre is a movie palace lo...       0.422826  \n",
       "3  Technische Universität Darmstadt is a renowned...       0.634715  \n",
       "4  Here's a suggestion for visiting England: Bost...       0.444070  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge import Rouge\n",
    "import bert_score\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add UniEval to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"UniEval\"))  # Update with your actual path\n",
    "\n",
    "from UniEval.utils import convert_to_json\n",
    "from UniEval.metric.evaluator import get_evaluator\n",
    "\n",
    "\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Lists to store the metrics\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "consistency_scores = []\n",
    "persona_distance_scores = []\n",
    "coh_unieval_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Initialize smoothing function\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_c_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the C score based on the entailment results between a generated response (R)\n",
    "    and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: C-score with possible values:\n",
    "         1 for entailment (positive),\n",
    "         0 for neutral,\n",
    "         -1 for contradiction (negative).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine C score based on entailment results\n",
    "    if label_pr == 'positive':\n",
    "        return 1\n",
    "    elif label_pr == 'neutral':\n",
    "        return 0\n",
    "    elif label_pr == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_consistency_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the Consistency Score based on the binary entailment results \n",
    "    between a generated response (R) and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: Consistency Score with binary values:\n",
    "         1 for entailment or neutral,\n",
    "         0 for contradiction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping for binary classification\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine Consistency Score based on binary entailment results\n",
    "    if label_pr in ['positive', 'neutral']:\n",
    "        return 1\n",
    "    elif label_pr == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_ue_score(act_response, gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the UE score based on entailment between persona, actual response, and generated response.\n",
    "\n",
    "    Returns:\n",
    "    int: UE score with possible values 2, 1, or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_snli(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Check entailment between actual response (Q) and generated response (R)\n",
    "    result_qr = bert_on_snli(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = label_mapping.get(result_qr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine UE score based on entailment results\n",
    "    if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "        return 2\n",
    "    elif label_pr == 'entailment':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calculate_coh_unieval_score(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (str or list): Conversation histories leading to the responses.\n",
    "        gen_responses (str or list): Generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        float: The coherence score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure personas is a list and flatten if necessary\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Ensure contexts and gen_responses are lists\n",
    "    if isinstance(contexts, str):\n",
    "        contexts = [contexts]  # Convert single string to list\n",
    "\n",
    "    if isinstance(gen_responses, str):\n",
    "        gen_responses = [gen_responses]  # Convert single string to list\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "    \n",
    "    # Extract and return only the first coherence score\n",
    "    return eval_scores[0].get(\"coherence\", None) if eval_scores else None\n",
    "\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_c_score = -1.0\n",
    "worst_consistency_score = 0.0\n",
    "worst_idf_score = 0.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0\n",
    "worst_coh_unieval_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [38:41<00:00,  2.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.068506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.997147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.398505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.997271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0       0.994554      0.0       0.0          0.330360\n",
       "1       0.993552      0.0       0.0          0.548835\n",
       "2       0.992067      0.0       0.0          0.477514\n",
       "3       0.996803      0.0       0.0          0.553215\n",
       "4       0.992959      0.0       2.0          0.548066\n",
       "..           ...      ...       ...               ...\n",
       "995     0.000000     -1.0       0.0          0.000000\n",
       "996     0.068506      0.0       0.0          0.273092\n",
       "997     0.000000     -1.0       0.0          0.000000\n",
       "998     0.997147      0.0       1.0          0.398505\n",
       "999     0.997271      1.0       1.0          0.433339\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    contexts = row['context']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "    \n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "    \n",
    "        c_scores.append(worst_c_score)\n",
    "        coh_unieval_scores.append(worst_coh_unieval_score)\n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        ue_scores.append(worst_ue_score)\n",
    "\n",
    "        continue\n",
    "\n",
    "    \n",
    "    coh_unieval_scores.append(calculate_coh_unieval_score(personas, contexts, gen_response)) \n",
    "    \n",
    "    c_scores.append(calculate_c_score(personas, gen_response))\n",
    "    \n",
    "    ue_scores.append(calculate_ue_score(act_response, gen_response, personas))                  \n",
    "\n",
    "    persona_distance_scores.append(compute_persona_distance(personas, gen_response, word2vec_model,\n",
    "                                                            stop_words))\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Coh-UniEval': coh_unieval_scores,\n",
    "    'C Score': c_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Storing the full results\n",
    "output_path = f'./Metrics Results/{DATASET}/{LLM}{COT_}-results.xlsx'\n",
    "\n",
    "df_concat = pd.concat([eval_df, metrics_df], axis=1)\n",
    "\n",
    "df_concat.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514938</td>\n",
       "      <td>0.994554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462074</td>\n",
       "      <td>0.993552</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.422826</td>\n",
       "      <td>0.992067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.634715</td>\n",
       "      <td>0.996803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444070</td>\n",
       "      <td>0.992959</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.548066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.884238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.409802</td>\n",
       "      <td>0.068506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.899150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.517449</td>\n",
       "      <td>0.997147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.745065</td>\n",
       "      <td>0.997271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     response_time  Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0         0.514938     0.994554        0         0          0.330360\n",
       "1         0.462074     0.993552        0         0          0.548835\n",
       "2         0.422826     0.992067        0         0          0.477514\n",
       "3         0.634715     0.996803        0         0          0.553215\n",
       "4         0.444070     0.992959        0         2          0.548066\n",
       "..             ...          ...      ...       ...               ...\n",
       "995       0.884238     0.000000       -1         0          0.000000\n",
       "996       0.409802     0.068506        0         0          0.273092\n",
       "997       0.899150     0.000000       -1         0          0.000000\n",
       "998       0.517449     0.997147        0         1          0.398505\n",
       "999       0.745065     0.997271        1         1          0.433339\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(f\"Metrics Results/{DATASET}/{LLM}-results.xlsx\")\n",
    "metrics_df = df.drop(columns=[\"personas\", \"context\", \"act_response\",\"gen_response\"])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-DPO-LENGTH-PRIOR</td>\n",
       "      <td>0.64 ± 0.18</td>\n",
       "      <td>0.73 ± 0.44</td>\n",
       "      <td>-0.07 ± 0.7</td>\n",
       "      <td>0.3 ± 0.64</td>\n",
       "      <td>0.37 ± 0.23</td>\n",
       "      <td>0.203 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model response_time  Coh-UniEval      C Score  \\\n",
       "0  Qwen2-5B-DPO-LENGTH-PRIOR   0.64 ± 0.18  0.73 ± 0.44  -0.07 ± 0.7   \n",
       "\n",
       "     UE Score Persona Distance Failure Ratio  \n",
       "0  0.3 ± 0.64      0.37 ± 0.23  0.203 ± 0.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = df['gen_response'].isna().sum() /len(df) \n",
    "\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-Benchmark</td>\n",
       "      <td>0.77 ± 0.16</td>\n",
       "      <td>0.6 ± 0.49</td>\n",
       "      <td>-0.24 ± 0.76</td>\n",
       "      <td>0.14 ± 0.45</td>\n",
       "      <td>0.3 ± 0.26</td>\n",
       "      <td>0.39 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-DPO-AVG</td>\n",
       "      <td>0.83 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-DPO-LENGTH-PRIOR</td>\n",
       "      <td>0.64 ± 0.18</td>\n",
       "      <td>0.73 ± 0.44</td>\n",
       "      <td>-0.07 ± 0.7</td>\n",
       "      <td>0.3 ± 0.64</td>\n",
       "      <td>0.37 ± 0.23</td>\n",
       "      <td>0.203 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model response_time  Coh-UniEval       C Score  \\\n",
       "0         Qwen2-5B-Benchmark   0.77 ± 0.16   0.6 ± 0.49  -0.24 ± 0.76   \n",
       "1           Qwen2-5B-DPO-AVG   0.83 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "2  Qwen2-5B-DPO-LENGTH-PRIOR   0.64 ± 0.18  0.73 ± 0.44   -0.07 ± 0.7   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.14 ± 0.45       0.3 ± 0.26   0.39 ± 0.00  \n",
       "1  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "2   0.3 ± 0.64      0.37 ± 0.23  0.203 ± 0.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{DATASET}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviwing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-Benchmark</td>\n",
       "      <td>0.77 ± 0.16</td>\n",
       "      <td>0.6 ± 0.49</td>\n",
       "      <td>-0.24 ± 0.76</td>\n",
       "      <td>0.14 ± 0.45</td>\n",
       "      <td>0.3 ± 0.26</td>\n",
       "      <td>0.39 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-DPO-AVG</td>\n",
       "      <td>0.83 ± 0.09</td>\n",
       "      <td>0.39 ± 0.48</td>\n",
       "      <td>-0.47 ± 0.76</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.28</td>\n",
       "      <td>0.595 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-DPO-LENGTH-PRIOR</td>\n",
       "      <td>0.64 ± 0.18</td>\n",
       "      <td>0.73 ± 0.44</td>\n",
       "      <td>-0.07 ± 0.7</td>\n",
       "      <td>0.3 ± 0.64</td>\n",
       "      <td>0.37 ± 0.23</td>\n",
       "      <td>0.203 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model response_time  Coh-UniEval       C Score  \\\n",
       "0         Qwen2-5B-Benchmark   0.77 ± 0.16   0.6 ± 0.49  -0.24 ± 0.76   \n",
       "1           Qwen2-5B-DPO-AVG   0.83 ± 0.09  0.39 ± 0.48  -0.47 ± 0.76   \n",
       "2  Qwen2-5B-DPO-LENGTH-PRIOR   0.64 ± 0.18  0.73 ± 0.44   -0.07 ± 0.7   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.14 ± 0.45       0.3 ± 0.26   0.39 ± 0.00  \n",
       "1  0.16 ± 0.48      0.22 ± 0.28  0.595 ± 0.00  \n",
       "2   0.3 ± 0.64      0.37 ± 0.23  0.203 ± 0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = \"FoCus\"  \n",
    "# COT_ = \"-COT\"\n",
    "COT_ =  \"\"\n",
    "\n",
    "response = pd.read_excel(f'./Evaluations/{DATASET}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
