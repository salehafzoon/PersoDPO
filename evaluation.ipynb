{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim requests rouge bert_score openpyxl prettytable nltk gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# import gzip\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# compressed_path = \"./GoogleNews-vectors-negative300.bin.gz\"\n",
    "# decompressed_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "\n",
    "# # Google Drive file ID extracted from the link\n",
    "# file_id = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
    "\n",
    "# # Download the file\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}&export=download\", compressed_path, quiet=False)\n",
    "\n",
    "# print(\"Download completed.\")\n",
    "\n",
    "\n",
    "# # Extract the .bin file from .gz\n",
    "# with gzip.open(compressed_path, \"rb\") as f_in:\n",
    "#     with open(decompressed_path, \"wb\") as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# print(\"Extraction completed.\")\n",
    "\n",
    "# # (Optional) Delete the .gz file after extraction\n",
    "# os.remove(compressed_path)\n",
    "# print(\"Deleted the compressed file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"FoCus\"                      \n",
    "\n",
    "COT_ = \"\"                                   #  \"\",    \"-COT\"\n",
    "\n",
    "# SET = \"train\"\n",
    "# LLM = f\"Qwen2-5B-Instruct-{SET}\"\n",
    "\n",
    "SCORING_METHOD = \"benchmark\"                      # \"avg\",  \"length_prior\", \"benchmark\"\n",
    "LLM = f\"Qwen2-5B-Instruct-{SCORING_METHOD}\"\n",
    "SET = \"valid\"\n",
    "\n",
    "COT_SETUP = True if COT_ == \"-COT\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{DATASET}-{SET}.csv')            #Only for train set\n",
    "\n",
    "# df = pd.read_csv(f'./Prompts/{DATASET}-{SET}.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "\n",
       "                                        act_response  \n",
       "0  The history of the house you are interested in...  \n",
       "1  This house was use as a stop for slaves trying...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "\n",
    "df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello! Welcome to Descent of the Ganges. It's ...</td>\n",
       "      <td>1.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The name of the place is Little Rock Central H...</td>\n",
       "      <td>0.959511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.069960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camp Randall Stadium is an outdoor stadium loc...</td>\n",
       "      <td>0.751485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Kõpu Lighthouse is a beautiful historical land...</td>\n",
       "      <td>0.657697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>St. Matthews Lutheran Church is a historic chu...</td>\n",
       "      <td>0.820268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>The bell has been restored to its original pos...</td>\n",
       "      <td>0.336838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>The castle is located in the northwest of the ...</td>\n",
       "      <td>0.873649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_response  response_time\n",
       "0     Hello! Welcome to Descent of the Ganges. It's ...       1.002536\n",
       "1     The name of the place is Little Rock Central H...       0.959511\n",
       "2                                                   NaN       1.069960\n",
       "3     Camp Randall Stadium is an outdoor stadium loc...       0.751485\n",
       "4                                                   NaN       0.904021\n",
       "...                                                 ...            ...\n",
       "3995                                                NaN       0.878556\n",
       "3996  Kõpu Lighthouse is a beautiful historical land...       0.657697\n",
       "3997  St. Matthews Lutheran Church is a historic chu...       0.820268\n",
       "3998  The bell has been restored to its original pos...       0.336838\n",
       "3999  The castle is located in the northwest of the ...       0.873649\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_csv(f'Responses/{DATASET}/{LLM}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 83\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas         3000\n",
      "context          3000\n",
      "act_response     3000\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "      <td>Hello! Welcome to Descent of the Ganges. It's ...</td>\n",
       "      <td>1.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "      <td>The name of the place is Little Rock Central H...</td>\n",
       "      <td>0.959511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.069960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "      <td>Camp Randall Stadium is an outdoor stadium loc...</td>\n",
       "      <td>0.751485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  The history of the house you are interested in...   \n",
       "1  This house was use as a stop for slaves trying...   \n",
       "2  Sure, you will like to know that this place wa...   \n",
       "3  Technische Universität Darmstadt in the top 25...   \n",
       "4  I suggest a place, for your wish of see librar...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Hello! Welcome to Descent of the Ganges. It's ...       1.002536  \n",
       "1  The name of the place is Little Rock Central H...       0.959511  \n",
       "2                                                NaN       1.069960  \n",
       "3  Camp Randall Stadium is an outdoor stadium loc...       0.751485  \n",
       "4                                                NaN       0.904021  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas         3000\n",
      "context          3000\n",
      "act_response     3000\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Add UniEval to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"UniEval\"))  # Update with your actual path\n",
    "\n",
    "from UniEval.utils import convert_to_json\n",
    "from UniEval.metric.evaluator import get_evaluator\n",
    "\n",
    "\n",
    "# Lists to store the metrics\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "persona_distance_scores = []\n",
    "coh_unieval_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_c_scores(gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_c_score using DNLI model.\n",
    "    \"\"\"\n",
    "    assert len(gen_responses) == len(personas), \"Mismatched input lengths\"\n",
    "\n",
    "    inputs = [f\"{p} {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    results = bert_on_dnli(inputs)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        label = label_mapping.get(result['label'], 'unknown')\n",
    "        if label == 'positive':\n",
    "            scores.append(1)\n",
    "        elif label == 'neutral':\n",
    "            scores.append(0)\n",
    "        elif label == 'negative':\n",
    "            scores.append(-1)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def batch_calculate_ue_scores(act_responses, gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_ue_score using SNLI model.\n",
    "    Returns a list of UE scores (0, 1, or 2).\n",
    "    \"\"\"\n",
    "    assert len(act_responses) == len(gen_responses) == len(personas), \"Mismatched lengths.\"\n",
    "\n",
    "    # Prepare NLI inputs\n",
    "    inputs_pr = [f\"{p} [SEP] {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    inputs_qr = [f\"{q} [SEP] {r}\" for q, r in zip(act_responses, gen_responses)]\n",
    "\n",
    "    # Run both batches\n",
    "    results_pr = bert_on_snli(inputs_pr)\n",
    "    results_qr = bert_on_snli(inputs_qr)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for res_pr, res_qr in zip(results_pr, results_qr):\n",
    "        label_pr = label_mapping.get(res_pr['label'], 'unknown')\n",
    "        label_qr = label_mapping.get(res_qr['label'], 'unknown')\n",
    "\n",
    "        if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "            scores.append(2)\n",
    "        elif label_pr == 'entailment':\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_coh_unieval_scores(personas_list, contexts_list, gen_responses_list):\n",
    "    \"\"\"\n",
    "    Batched coherence scoring using UniEval evaluator.\n",
    "    \"\"\"\n",
    "    # Ensure personas are joined as single strings\n",
    "    personas_list = [' '.join(p) if isinstance(p, list) else p for p in personas_list]\n",
    "    \n",
    "    # Convert to UniEval input format\n",
    "    data = convert_to_json(\n",
    "        output_list=gen_responses_list,\n",
    "        src_list=contexts_list,\n",
    "        context_list=personas_list\n",
    "    )\n",
    "    \n",
    "    # Load UniEval dialogue evaluator only once\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    # Extract coherence scores\n",
    "    return [s.get(\"coherence\", None) for s in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_c_score = -1.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0\n",
    "worst_coh_unieval_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating C Scores...\n",
      "Calculating UE Scores...\n",
      "Calculating UniEval Coherence Scores...\n",
      "Filling final metric arrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating Scores: 100%|██████████| 392/392 [00:00<00:00, 2601530.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Identify valid rows (non-null gen_response)\n",
    "valid_mask = eval_df['gen_response'].notna()\n",
    "valid_indices = eval_df[valid_mask].index.tolist()\n",
    "\n",
    "# Extract valid inputs\n",
    "valid_personas = eval_df.loc[valid_indices, 'personas'].tolist()\n",
    "valid_act_responses = eval_df.loc[valid_indices, 'act_response'].tolist()\n",
    "valid_contexts = eval_df.loc[valid_indices, 'context'].tolist()\n",
    "valid_gen_responses = eval_df.loc[valid_indices, 'gen_response'].tolist()\n",
    "\n",
    "# === Compute batch metrics with tqdm logging ===\n",
    "print(\"Calculating C Scores...\")\n",
    "c_scores_batch = batch_calculate_c_scores(valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UE Scores...\")\n",
    "ue_scores_batch = batch_calculate_ue_scores(valid_act_responses, valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UniEval Coherence Scores...\")\n",
    "coh_unieval_batch_scores = batch_calculate_coh_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "\n",
    "# Initialize all score lists with worst-case values\n",
    "c_scores = [worst_c_score] * len(eval_df)\n",
    "ue_scores = [worst_ue_score] * len(eval_df)\n",
    "coh_unieval_scores = [worst_coh_unieval_score] * len(eval_df)\n",
    "\n",
    "# Fill valid indices with batch results using progress bar\n",
    "print(\"Filling final metric arrays...\")\n",
    "for i, c, ue, coh in tqdm(zip(valid_indices, c_scores_batch, ue_scores_batch, coh_unieval_batch_scores),\n",
    "                          total=len(valid_indices), desc=\"Populating Scores\"):\n",
    "    c_scores[i] = c\n",
    "    ue_scores[i] = ue\n",
    "    coh_unieval_scores[i] = coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 7463.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.997533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.992111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0       0.000000     -1.0       0.0          0.000000\n",
       "1       0.000000     -1.0       0.0          0.000000\n",
       "2       0.000000     -1.0       0.0          0.000000\n",
       "3       0.997231      0.0       0.0          0.719056\n",
       "4       0.907556      0.0       0.0          0.762630\n",
       "..           ...      ...       ...               ...\n",
       "995     0.997533      0.0       0.0          0.508108\n",
       "996     0.999099      0.0       0.0          0.472125\n",
       "997     0.992111      1.0       1.0          0.465782\n",
       "998     0.999163      0.0       0.0          0.522185\n",
       "999     0.000000     -1.0       0.0          0.000000\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    contexts = row['context']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "    \n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "    \n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    persona_distance_scores.append(compute_persona_distance(personas, gen_response, word2vec_model,stop_words))\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Coh-UniEval': coh_unieval_scores,\n",
    "    'C Score': c_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the full results\n",
    "output_path = f'./Metrics Results/{DATASET}/{LLM}{COT_}-results.xlsx'\n",
    "\n",
    "df_concat = pd.concat([eval_df, metrics_df], axis=1)\n",
    "\n",
    "df_concat.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484737</td>\n",
       "      <td>0.997231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887493</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.631824</td>\n",
       "      <td>0.997533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.539604</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.606732</td>\n",
       "      <td>0.992111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.694164</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.896740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     response_time  Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0         0.349829     0.000000       -1         0          0.000000\n",
       "1         0.108759     0.000000       -1         0          0.000000\n",
       "2         0.487043     0.000000       -1         0          0.000000\n",
       "3         0.484737     0.997231        0         0          0.719056\n",
       "4         0.887493     0.907556        0         0          0.762630\n",
       "..             ...          ...      ...       ...               ...\n",
       "995       0.631824     0.997533        0         0          0.508108\n",
       "996       0.539604     0.999099        0         0          0.472125\n",
       "997       0.606732     0.992111        1         1          0.465782\n",
       "998       0.694164     0.999163        0         0          0.522185\n",
       "999       0.896740     0.000000       -1         0          0.000000\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(f\"Metrics Results/{DATASET}/{LLM}-results.xlsx\")\n",
    "metrics_df = df.drop(columns=[\"personas\", \"context\", \"act_response\",\"gen_response\"])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = df['gen_response'].isna().sum() /len(df) \n",
    "\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-benchmark</td>\n",
       "      <td>4.02 ± 0.48</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-avg</td>\n",
       "      <td>0.63 ± 0.25</td>\n",
       "      <td>0.24 ± 0.42</td>\n",
       "      <td>-0.61 ± 0.67</td>\n",
       "      <td>0.08 ± 0.35</td>\n",
       "      <td>0.16 ± 0.26</td>\n",
       "      <td>0.712 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0     Qwen2-7B-benchmark   4.02 ± 0.48  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "1           Qwen2-5B-avg   0.63 ± 0.25  0.24 ± 0.42  -0.61 ± 0.67   \n",
       "2  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.16 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  \n",
       "1  0.08 ± 0.35      0.16 ± 0.26  0.712 ± 0.00  \n",
       "2  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{DATASET}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviwing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-benchmark</td>\n",
       "      <td>4.02 ± 0.48</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-avg</td>\n",
       "      <td>0.63 ± 0.25</td>\n",
       "      <td>0.24 ± 0.42</td>\n",
       "      <td>-0.61 ± 0.67</td>\n",
       "      <td>0.08 ± 0.35</td>\n",
       "      <td>0.16 ± 0.26</td>\n",
       "      <td>0.712 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0     Qwen2-7B-benchmark   4.02 ± 0.48  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "1           Qwen2-5B-avg   0.63 ± 0.25  0.24 ± 0.42  -0.61 ± 0.67   \n",
       "2  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.16 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  \n",
       "1  0.08 ± 0.35      0.16 ± 0.26  0.712 ± 0.00  \n",
       "2  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET = \"FoCus\"  \n",
    "## COT_ = \"\"\n",
    "\n",
    "\n",
    "response = pd.read_excel(f'./Evaluations/{DATASET}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
