{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim requests rouge bert_score openpyxl prettytable nltk gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# import gzip\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# compressed_path = \"./GoogleNews-vectors-negative300.bin.gz\"\n",
    "# decompressed_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "\n",
    "# # Google Drive file ID extracted from the link\n",
    "# file_id = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
    "\n",
    "# # Download the file\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}&export=download\", compressed_path, quiet=False)\n",
    "\n",
    "# print(\"Download completed.\")\n",
    "\n",
    "\n",
    "# # Extract the .bin file from .gz\n",
    "# with gzip.open(compressed_path, \"rb\") as f_in:\n",
    "#     with open(decompressed_path, \"wb\") as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# print(\"Extraction completed.\")\n",
    "\n",
    "# # (Optional) Delete the .gz file after extraction\n",
    "# os.remove(compressed_path)\n",
    "# print(\"Deleted the compressed file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"FoCus\"                      \n",
    "\n",
    "COT_ = \"\"                                   #  \"\",    \"-COT\"\n",
    "\n",
    "# SET = \"train\"\n",
    "# LLM = f\"Qwen2-5B-Instruct-{SET}\"\n",
    "\n",
    "SCORING_METHOD = \"benchmark\"                      # \"avg\",  \"length_prior\", \"benchmark\"\n",
    "LLM = f\"Qwen2-5B-Instruct-{SCORING_METHOD}\"\n",
    "SET = \"train\"\n",
    "\n",
    "COT_SETUP = True if COT_ == \"-COT\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: You can access Descent of the Ganges vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>User2: It was Sherman School.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: You can access Descent of the Ganges vi...  \n",
       "1                      User2: It was Sherman School.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{DATASET}-{SET}.csv')            #Only for train set\n",
    "\n",
    "# df = pd.read_csv(f'./Prompts/{DATASET}-{SET}.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>You can access Descent of the Ganges via Chenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It was Sherman School.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "\n",
       "                                        act_response  \n",
       "0  You can access Descent of the Ganges via Chenn...  \n",
       "1                             It was Sherman School.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "\n",
    "df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello! Welcome to Descent of the Ganges. It's ...</td>\n",
       "      <td>0.790489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The name of the place is Little Rock Central H...</td>\n",
       "      <td>0.744353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camp Randall Stadium is an outdoor stadium loc...</td>\n",
       "      <td>0.747605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Kõpu Lighthouse is a beautiful historical land...</td>\n",
       "      <td>0.676165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>St. Matthews Lutheran Church is a historic chu...</td>\n",
       "      <td>0.828035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>The bell has been restored to its original pos...</td>\n",
       "      <td>0.339198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>The castle is located in the northwest of the ...</td>\n",
       "      <td>0.879601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_response  response_time\n",
       "0     Hello! Welcome to Descent of the Ganges. It's ...       0.790489\n",
       "1     The name of the place is Little Rock Central H...       0.744353\n",
       "2                                                   NaN       0.895105\n",
       "3     Camp Randall Stadium is an outdoor stadium loc...       0.747605\n",
       "4                                                   NaN       0.898532\n",
       "...                                                 ...            ...\n",
       "3995                                                NaN       0.895923\n",
       "3996  Kõpu Lighthouse is a beautiful historical land...       0.676165\n",
       "3997  St. Matthews Lutheran Church is a historic chu...       0.828035\n",
       "3998  The bell has been restored to its original pos...       0.339198\n",
       "3999  The castle is located in the northwest of the ...       0.879601\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_csv(f'Responses/{DATASET}/{LLM}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 83\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas            0\n",
      "context             0\n",
      "act_response        0\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id like to visit a historic place.I want to vi...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>You can access Descent of the Ganges via Chenn...</td>\n",
       "      <td>Hello! Welcome to Descent of the Ganges. It's ...</td>\n",
       "      <td>0.790489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hope to see some rock in Little Rock.I like ...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It was Sherman School.</td>\n",
       "      <td>The name of the place is Little Rock Central H...</td>\n",
       "      <td>0.744353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love cool lakes.I would like to visit the Hi...</td>\n",
       "      <td>User1: I know this place, but I dont remember ...</td>\n",
       "      <td>It formed from being a tributary of the Ravi R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I prefer outdoor stadium over indoor stadium.I...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I just remembered that you are interested in N...</td>\n",
       "      <td>Camp Randall Stadium is an outdoor stadium loc...</td>\n",
       "      <td>0.747605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would like to visit Spain.I am interested in...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This is Ur...</td>\n",
       "      <td>Urdaibai Bird Center deals with two main tasks...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  Id like to visit a historic place.I want to vi...   \n",
       "1  I hope to see some rock in Little Rock.I like ...   \n",
       "2  I love cool lakes.I would like to visit the Hi...   \n",
       "3  I prefer outdoor stadium over indoor stadium.I...   \n",
       "4  I would like to visit Spain.I am interested in...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "1  User1: I know this place, but I dont remember ...   \n",
       "2  User1: I know this place, but I dont remember ...   \n",
       "3  User1: Where is this place?\\nUser2: This place...   \n",
       "4  User1: Where is this place?\\nUser2: This is Ur...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  You can access Descent of the Ganges via Chenn...   \n",
       "1                             It was Sherman School.   \n",
       "2  It formed from being a tributary of the Ravi R...   \n",
       "3  I just remembered that you are interested in N...   \n",
       "4  Urdaibai Bird Center deals with two main tasks...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Hello! Welcome to Descent of the Ganges. It's ...       0.790489  \n",
       "1  The name of the place is Little Rock Central H...       0.744353  \n",
       "2                                                NaN       0.895105  \n",
       "3  Camp Randall Stadium is an outdoor stadium loc...       0.747605  \n",
       "4                                                NaN       0.898532  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas            0\n",
      "context             0\n",
      "act_response        0\n",
      "gen_response     1536\n",
      "response_time       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Add UniEval to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"UniEval\"))  # Update with your actual path\n",
    "\n",
    "from UniEval.utils import convert_to_json\n",
    "from UniEval.metric.evaluator import get_evaluator\n",
    "\n",
    "\n",
    "# Lists to store the metrics\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "persona_distance_scores = []\n",
    "coh_unieval_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_c_scores(gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_c_score using DNLI model.\n",
    "    \"\"\"\n",
    "    assert len(gen_responses) == len(personas), \"Mismatched input lengths\"\n",
    "\n",
    "    inputs = [f\"{p} {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    results = bert_on_dnli(inputs)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        label = label_mapping.get(result['label'], 'unknown')\n",
    "        if label == 'positive':\n",
    "            scores.append(1)\n",
    "        elif label == 'neutral':\n",
    "            scores.append(0)\n",
    "        elif label == 'negative':\n",
    "            scores.append(-1)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def batch_calculate_ue_scores(act_responses, gen_responses, personas):\n",
    "    \"\"\"\n",
    "    Batched version of calculate_ue_score using SNLI model.\n",
    "    Returns a list of UE scores (0, 1, or 2).\n",
    "    \"\"\"\n",
    "    assert len(act_responses) == len(gen_responses) == len(personas), \"Mismatched lengths.\"\n",
    "\n",
    "    # Prepare NLI inputs\n",
    "    inputs_pr = [f\"{p} [SEP] {r}\" for p, r in zip(personas, gen_responses)]\n",
    "    inputs_qr = [f\"{q} [SEP] {r}\" for q, r in zip(act_responses, gen_responses)]\n",
    "\n",
    "    # Run both batches\n",
    "    results_pr = bert_on_snli(inputs_pr)\n",
    "    results_qr = bert_on_snli(inputs_qr)\n",
    "\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for res_pr, res_qr in zip(results_pr, results_qr):\n",
    "        label_pr = label_mapping.get(res_pr['label'], 'unknown')\n",
    "        label_qr = label_mapping.get(res_qr['label'], 'unknown')\n",
    "\n",
    "        if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "            scores.append(2)\n",
    "        elif label_pr == 'entailment':\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def batch_calculate_coh_unieval_scores(personas_list, contexts_list, gen_responses_list):\n",
    "    \"\"\"\n",
    "    Batched coherence scoring using UniEval evaluator.\n",
    "    \"\"\"\n",
    "    # Ensure personas are joined as single strings\n",
    "    personas_list = [' '.join(p) if isinstance(p, list) else p for p in personas_list]\n",
    "    \n",
    "    # Convert to UniEval input format\n",
    "    data = convert_to_json(\n",
    "        output_list=gen_responses_list,\n",
    "        src_list=contexts_list,\n",
    "        context_list=personas_list\n",
    "    )\n",
    "    \n",
    "    # Load UniEval dialogue evaluator only once\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    # Extract coherence scores\n",
    "    return [s.get(\"coherence\", None) for s in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_c_score = -1.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0\n",
    "worst_coh_unieval_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating C Scores...\n",
      "Calculating UE Scores...\n",
      "Calculating UniEval Coherence Scores...\n",
      "Filling final metric arrays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating Scores: 100%|██████████| 2464/2464 [00:00<00:00, 3627506.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Identify valid rows (non-null gen_response)\n",
    "valid_mask = eval_df['gen_response'].notna()\n",
    "valid_indices = eval_df[valid_mask].index.tolist()\n",
    "\n",
    "# Extract valid inputs\n",
    "valid_personas = eval_df.loc[valid_indices, 'personas'].tolist()\n",
    "valid_act_responses = eval_df.loc[valid_indices, 'act_response'].tolist()\n",
    "valid_contexts = eval_df.loc[valid_indices, 'context'].tolist()\n",
    "valid_gen_responses = eval_df.loc[valid_indices, 'gen_response'].tolist()\n",
    "\n",
    "# === Compute batch metrics with tqdm logging ===\n",
    "print(\"Calculating C Scores...\")\n",
    "c_scores_batch = batch_calculate_c_scores(valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UE Scores...\")\n",
    "ue_scores_batch = batch_calculate_ue_scores(valid_act_responses, valid_gen_responses, valid_personas)\n",
    "\n",
    "print(\"Calculating UniEval Coherence Scores...\")\n",
    "coh_unieval_batch_scores = batch_calculate_coh_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "\n",
    "# Initialize all score lists with worst-case values\n",
    "c_scores = [worst_c_score] * len(eval_df)\n",
    "ue_scores = [worst_ue_score] * len(eval_df)\n",
    "coh_unieval_scores = [worst_coh_unieval_score] * len(eval_df)\n",
    "\n",
    "# Fill valid indices with batch results using progress bar\n",
    "print(\"Filling final metric arrays...\")\n",
    "for i, c, ue, coh in tqdm(zip(valid_indices, c_scores_batch, ue_scores_batch, coh_unieval_batch_scores),\n",
    "                          total=len(valid_indices), desc=\"Populating Scores\"):\n",
    "    c_scores[i] = c\n",
    "    ue_scores[i] = ue\n",
    "    coh_unieval_scores[i] = coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 5189.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.604749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.998415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.966287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.996589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0        0.998912      1.0       0.0          0.430646\n",
       "1        0.994791      0.0       2.0          0.604749\n",
       "2        0.000000     -1.0       0.0          0.000000\n",
       "3        0.996146      1.0       0.0          0.685219\n",
       "4        0.000000     -1.0       0.0          0.000000\n",
       "...           ...      ...       ...               ...\n",
       "3995     0.000000     -1.0       0.0          0.000000\n",
       "3996     0.998415      1.0       0.0          0.463135\n",
       "3997     0.966287      0.0       1.0          0.533171\n",
       "3998     0.998227      0.0       0.0          0.210042\n",
       "3999     0.996589      1.0       0.0          0.432606\n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    contexts = row['context']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "    \n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "    \n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        \n",
    "        continue\n",
    "\n",
    "    persona_distance_scores.append(compute_persona_distance(personas, gen_response, word2vec_model,stop_words))\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Coh-UniEval': coh_unieval_scores,\n",
    "    'C Score': c_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the full results\n",
    "output_path = f'./Metrics Results/{DATASET}/{LLM}{COT_}-results.xlsx'\n",
    "\n",
    "df_concat = pd.concat([eval_df, metrics_df], axis=1)\n",
    "\n",
    "df_concat.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484737</td>\n",
       "      <td>0.997231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887493</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.631824</td>\n",
       "      <td>0.997533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.539604</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.606732</td>\n",
       "      <td>0.992111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.694164</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.896740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     response_time  Coh-UniEval  C Score  UE Score  Persona Distance\n",
       "0         0.349829     0.000000       -1         0          0.000000\n",
       "1         0.108759     0.000000       -1         0          0.000000\n",
       "2         0.487043     0.000000       -1         0          0.000000\n",
       "3         0.484737     0.997231        0         0          0.719056\n",
       "4         0.887493     0.907556        0         0          0.762630\n",
       "..             ...          ...      ...       ...               ...\n",
       "995       0.631824     0.997533        0         0          0.508108\n",
       "996       0.539604     0.999099        0         0          0.472125\n",
       "997       0.606732     0.992111        1         1          0.465782\n",
       "998       0.694164     0.999163        0         0          0.522185\n",
       "999       0.896740     0.000000       -1         0          0.000000\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(f\"Metrics Results/{DATASET}/{LLM}-results.xlsx\")\n",
    "metrics_df = df.drop(columns=[\"personas\", \"context\", \"act_response\",\"gen_response\"])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = df['gen_response'].isna().sum() /len(df) \n",
    "\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-benchmark</td>\n",
       "      <td>4.02 ± 0.48</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-avg</td>\n",
       "      <td>0.63 ± 0.25</td>\n",
       "      <td>0.24 ± 0.42</td>\n",
       "      <td>-0.61 ± 0.67</td>\n",
       "      <td>0.08 ± 0.35</td>\n",
       "      <td>0.16 ± 0.26</td>\n",
       "      <td>0.712 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0     Qwen2-7B-benchmark   4.02 ± 0.48  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "1           Qwen2-5B-avg   0.63 ± 0.25  0.24 ± 0.42  -0.61 ± 0.67   \n",
       "2  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.16 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  \n",
       "1  0.08 ± 0.35      0.16 ± 0.26  0.712 ± 0.00  \n",
       "2  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{DATASET}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviwing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Coh-UniEval</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2-7B-benchmark</td>\n",
       "      <td>4.02 ± 0.48</td>\n",
       "      <td>0.37 ± 0.48</td>\n",
       "      <td>-0.37 ± 0.87</td>\n",
       "      <td>0.16 ± 0.48</td>\n",
       "      <td>0.22 ± 0.29</td>\n",
       "      <td>0.627 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen2-5B-avg</td>\n",
       "      <td>0.63 ± 0.25</td>\n",
       "      <td>0.24 ± 0.42</td>\n",
       "      <td>-0.61 ± 0.67</td>\n",
       "      <td>0.08 ± 0.35</td>\n",
       "      <td>0.16 ± 0.26</td>\n",
       "      <td>0.712 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-5B-length_prior</td>\n",
       "      <td>0.45 ± 0.23</td>\n",
       "      <td>0.38 ± 0.48</td>\n",
       "      <td>-0.53 ± 0.67</td>\n",
       "      <td>0.09 ± 0.36</td>\n",
       "      <td>0.21 ± 0.27</td>\n",
       "      <td>0.608 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model response_time  Coh-UniEval       C Score  \\\n",
       "0     Qwen2-7B-benchmark   4.02 ± 0.48  0.37 ± 0.48  -0.37 ± 0.87   \n",
       "1           Qwen2-5B-avg   0.63 ± 0.25  0.24 ± 0.42  -0.61 ± 0.67   \n",
       "2  Qwen2-5B-length_prior   0.45 ± 0.23  0.38 ± 0.48  -0.53 ± 0.67   \n",
       "\n",
       "      UE Score Persona Distance Failure Ratio  \n",
       "0  0.16 ± 0.48      0.22 ± 0.29  0.627 ± 0.00  \n",
       "1  0.08 ± 0.35      0.16 ± 0.26  0.712 ± 0.00  \n",
       "2  0.09 ± 0.36      0.21 ± 0.27  0.608 ± 0.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET = \"FoCus\"  \n",
    "## COT_ = \"\"\n",
    "\n",
    "\n",
    "response = pd.read_excel(f'./Evaluations/{DATASET}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
